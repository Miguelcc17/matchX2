{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ivan Rivas\\Documents\\project\\matchX2\\.venv\\Lib\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "import matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toolkit_detect_language(file_path: str = None, columns: bool = False)->dict: \n",
    "    if file_path is None or len(file_path) == 0:\n",
    "        raise ValueError(\"'file_path' cannot be empty\")\n",
    "    if type(file_path) != str:\n",
    "        raise TypeError(\"data type compatible only 'str'\")\n",
    "    if type(columns) != bool:\n",
    "        raise TypeError('Columns must be bool')\n",
    "    from transformers import pipeline\n",
    "    pipe = pipeline(\"text-classification\", model=\"ImranzamanML/GEFS-language-detector\")\n",
    "    max_length = 2187\n",
    "    def split_text(text, max_length):\n",
    "        words = text.split()  \n",
    "        words_selected = []\n",
    "        currency_length = 0\n",
    "        for word in words:\n",
    "            if currency_length + len(word) + sum(map(len, words_selected)) <= max_length:\n",
    "                words_selected.append(word)\n",
    "                currency_length += len(word)\n",
    "            else:\n",
    "                break       \n",
    "        return ' '.join(words_selected)\n",
    "    df = matcher.get_df(file_path)\n",
    "    if not columns:         \n",
    "        text_combined = ' '.join(df.apply(lambda row: ', '.join(row.astype(str).unique()), axis=1))\n",
    "        texto_cortado = split_text(text_combined, max_length)\n",
    "        return pipe(texto_cortado)[0]['label']  \n",
    "    # Convert each column to a text series and get unique values\n",
    "    unique_values_by_column = df.apply(lambda col: col.astype(str).unique())\n",
    "    # Iterate over the keys of the dictionary of unique values by column\n",
    "    for column_name, values in unique_values_by_column.items():\n",
    "        # Join the unique values into a single string\n",
    "        complete_text = ' '.join(values)       \n",
    "        # Split the text into segments\n",
    "        divided_text = split_text(complete_text, max_length) \n",
    "        unique_values_by_column[column_name] = pipe(divided_text)[0]['label']\n",
    "    return unique_values_by_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fr'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filePath = \"files/origin_Madison.csv\"\n",
    "toolkit_detect_language(file_path=filePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-classification\", model=\"ImranzamanML/GEFS-language-detector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'es', 'score': 0.9999878406524658}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe('hola como estas, hello')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
